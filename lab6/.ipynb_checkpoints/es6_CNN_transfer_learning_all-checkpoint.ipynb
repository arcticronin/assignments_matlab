{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shbM3zJAuPI9"
      },
      "source": [
        "In this lab you will do the following steps in order:\n",
        "\n",
        "1. Load a new dataset using ``torchvision dataloader``\n",
        "2. Perform transfer learning of a pre-trained NN (Neural Network)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZW_s0fsB1Xi"
      },
      "source": [
        "\n",
        "Useful resources:\n",
        "\n",
        "* [dataloader](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)\n",
        "*   [network layers](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
        "*   [activation function](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
        "*   [loss functions](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F0vCe0kzcJ9"
      },
      "source": [
        "Use GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bun1lQdwoqy"
      },
      "outputs": [],
      "source": [
        "import torch  # Import the PyTorch library\n",
        "\n",
        "# Check if GPU (Graphics Processing Unit) is available for training\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "\n",
        "# Define the device to use for training based on GPU availability\n",
        "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
        "\n",
        "# Print the chosen device for training\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYFtM4aXT0JM"
      },
      "source": [
        "Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDRKuw5pGBnW"
      },
      "outputs": [],
      "source": [
        "#download images\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n",
        "#download metadata\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_meta.tar\n",
        "#extract\n",
        "!tar -xf imdb_crop.tar\n",
        "!tar -xf imdb_meta.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQBhFMSzpFFA"
      },
      "source": [
        "Remove grayscale images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySjydzAfS1mK"
      },
      "outputs": [],
      "source": [
        "import glob  # Import library for finding all files matching a pattern\n",
        "from PIL import Image  # Import library for image processing\n",
        "import numpy as np  # Import library for numerical operations (not used here)\n",
        "import os  # Import library for operating system functionalities\n",
        "\n",
        "# Define a path pattern to search for all jpg images within subdirectories of \"/content/imdb_crop\"\n",
        "image_path_pattern = \"/content/imdb_crop/*/*.jpg\"\n",
        "\n",
        "# Find all image file paths matching the pattern\n",
        "image_paths = glob.glob(image_path_pattern)\n",
        "\n",
        "# Iterate through each image path\n",
        "for image_path in image_paths:\n",
        "  # Open the image using Pillow's Image class\n",
        "  image = Image.open(image_path)\n",
        "\n",
        "  # Get the number of color channels in the image (e.g., RGB has 3 channels)\n",
        "  num_channels = len(image.getbands())\n",
        "\n",
        "  # Check if the image has a different number of channels than expected (likely grayscale or unsupported format)\n",
        "  if num_channels != 3:\n",
        "    # If not 3 channels, remove the image file\n",
        "    os.remove(image_path)\n",
        "    # print(f\"Removed {image_path} (not RGB format)\")  # Print statement to show removed files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEXVvskp2Q4s"
      },
      "source": [
        "Define function to convert numeric date to common date format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW-6cXo249Tz"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta  # Import libraries for date and time manipulation\n",
        "\n",
        "def datenum_to_datetime(datenum):\n",
        "  \"\"\"\n",
        "  Converts a date represented as a floating-point number (Excel-style) to a Python datetime object.\n",
        "\n",
        "  Args:\n",
        "      datenum (float): The date represented as a floating-point number.\n",
        "\n",
        "  Returns:\n",
        "      datetime: The converted datetime object (year only if conversion fails).\n",
        "          If conversion fails due to ValueError, TypeError, or OverflowError,\n",
        "          returns np.nan.\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Extract components from the datenum\n",
        "    days = datenum % 1  # Extract days (decimal part)\n",
        "    hours = days % 1 * 24  # Extract hours from remaining decimal part\n",
        "    minutes = hours % 1 * 60  # Extract minutes from remaining decimal part\n",
        "    seconds = minutes % 1 * 60  # Extract seconds from remaining decimal part\n",
        "\n",
        "    # Convert to datetime object with separate day, hour, minute, and second components\n",
        "    exact_date = (datetime.fromordinal(int(datenum))  # Convert integer part to date\n",
        "                 + timedelta(days=int(days))  # Add extracted days\n",
        "                 + timedelta(hours=int(hours))  # Add extracted hours\n",
        "                 + timedelta(minutes=int(minutes))  # Add extracted minutes\n",
        "                 + timedelta(seconds=round(seconds)))  # Add extracted seconds (rounded)\n",
        "\n",
        "    # Adjust for Excel's epoch being different from standard epoch (correct for year)\n",
        "    exact_date -= timedelta(days=366)\n",
        "\n",
        "    # Return the year from the converted datetime object\n",
        "    return exact_date.year\n",
        "\n",
        "  except (ValueError, TypeError, OverflowError) as e:\n",
        "    return np.nan  # Return np.nan if conversion fails\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEw-vwCipUeG"
      },
      "source": [
        "Define the [dataloader](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class) class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JAnWr6T0d8r"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import torch\n",
        "import collections\n",
        "\n",
        "class FacesDataset(Dataset):\n",
        "      \"\"\"Face Landmarks dataset.\n",
        "\n",
        "      This class loads and preprocesses a dataset of face images with corresponding ages.\n",
        "      It supports train, validation, and test splits.\n",
        "      \"\"\"\n",
        "\n",
        "      def __init__(self, root_dir, transform, split):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory containing the images.\n",
        "            transform (callable, optional): Transformation to be applied to the images.\n",
        "            split (string): Split type (\"train\", \"val\", or \"test\").\n",
        "        \"\"\"\n",
        "        self.split=split\n",
        "        self.root_dir = root_dir\n",
        "        self.data = self.get_data()  # Load and preprocess data\n",
        "        total_data_len = int(len(self.data) * 0.5)  # Select small portion of the dataset\n",
        "\n",
        "        # Randomly shuffle indices for train/val/test split\n",
        "        idx = np.arange(total_data_len)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(idx)\n",
        "        print(f\"Shuffled indices (first 5): {idx[:5]}\")  # Print first 5 shuffled indices\n",
        "\n",
        "        # Select data based on split\n",
        "        if split == \"train\":\n",
        "            self.data = self.data[idx[:int(total_data_len * 0.6)]]\n",
        "        elif split == \"val\":\n",
        "            self.data = self.data[int(total_data_len * 0.6):int(total_data_len * 0.8)]\n",
        "        else:\n",
        "            self.data = self.data[int(total_data_len * 0.8):]\n",
        "\n",
        "        # Analyze age distribution (uncomment to print)\n",
        "        # age_distribution = collections.Counter()\n",
        "        # for i, sample in enumerate(self.data):\n",
        "        #     age_distribution[sample[1]] += 1\n",
        "        # print(age_distribution)  # Uncomment to print the Counter object\n",
        "\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "\n",
        "      def get_data(self):\n",
        "        \"\"\"\n",
        "        Loads and preprocesses data from the IMDB dataset (.MAT file).\n",
        "\n",
        "        This function performs the following steps:\n",
        "            1. Loads data from the MAT file using scipy.io.loadmat.\n",
        "            2. Defines column names for the loaded data.\n",
        "            3. Converts the loaded data into a dictionary.\n",
        "            4. Creates a pandas DataFrame for efficient data manipulation.\n",
        "            5. Prints DataFrame shape and the first few rows (before processing).\n",
        "            6. Converts date of birth to age using vectorized operations.\n",
        "            7. Filters images based on face score and presence of a single face.\n",
        "                - Removes images without a face (face_score != -np.inf).\n",
        "                - Ensures only one face is present (second_face_score.isna()).\n",
        "                - Filters based on minimum face score threshold (face_score >= 3.5).\n",
        "                - Filters for valid age range (0 <= age <= 100).\n",
        "                - Converts age to integer and drops unnecessary columns.\n",
        "            8. Constructs full image paths by prepending the root directory.\n",
        "            9. Filters for images with existing paths using vectorized boolean indexing.\n",
        "            10. Prints DataFrame shape and the first few rows (after processing).\n",
        "            11. Returns the preprocessed data as a NumPy array.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load data from MAT file and define column names\n",
        "        mat_imdb = scipy.io.loadmat('/content/imdb/imdb.mat')\n",
        "        columns = [\"full_path\", \"dob\", \"photo_taken\", \"second_face_score\", \"face_score\"]\n",
        "\n",
        "        # Convert loaded data into a dictionary\n",
        "        data_dict = {col: mat_imdb['imdb'][0][0][col][0] for col in columns}\n",
        "\n",
        "        # Create pandas DataFrame for efficient data manipulation\n",
        "        df_imdb = pd.DataFrame(data_dict)\n",
        "        if self.split==\"train\":\n",
        "          print(\"Before processing:\")\n",
        "          print(df_imdb.shape)  # Print DataFrame shape\n",
        "          print(df_imdb.head())  # Print the first few rows\n",
        "\n",
        "        # Convert date of birth to age using vectorized operations\n",
        "        df_imdb['date_of_birth'] = df_imdb['dob'].apply(datenum_to_datetime)\n",
        "        df_imdb['age'] = df_imdb['photo_taken'].sub(df_imdb['date_of_birth'])  # Handle potential NaNs\n",
        "\n",
        "        # Filter images based on face score and presence of a single face\n",
        "        df_imdb = df_imdb[df_imdb['face_score'] != -np.inf]  # Remove images without a face\n",
        "        df_imdb = df_imdb[df_imdb['second_face_score'].isna()]  # Ensure only one face is present\n",
        "        df_imdb = df_imdb[df_imdb['face_score'] >= 3.5]  # Filter based on minimum face score threshold\n",
        "        df_imdb = df_imdb[(df_imdb['age'] <= 100) & (df_imdb['age'] >= 0)]  # Filter for valid age range\n",
        "        df_imdb['age'] = df_imdb['age'].apply(lambda x: int(x))  # Convert age to integer\n",
        "        df_imdb = df_imdb.drop(columns=['date_of_birth', 'dob', 'photo_taken', \"second_face_score\", \"face_score\"])  # Remove unnecessary columns\n",
        "\n",
        "        # Construct full image paths using vectorized operations\n",
        "        df_imdb['full_path'] = self.root_dir+\"/\"+ df_imdb['full_path'].apply(lambda x: x[0])\n",
        "\n",
        "        # Filter for images with existing paths using vectorized boolean indexing\n",
        "        df_imdb = df_imdb[df_imdb['full_path'].apply(os.path.exists)]\n",
        "\n",
        "        if self.split==\"train\":\n",
        "          print(\"After processing:\")\n",
        "          print(df_imdb.shape)  # Print DataFrame shape\n",
        "          print(df_imdb.head())  # Print the first few rows\n",
        "\n",
        "        return df_imdb.to_numpy()  # Return preprocessed data as a NumPy array\n",
        "\n",
        "      def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the length of the dataset (number of samples).\n",
        "\n",
        "        This method overrides the default behavior of `len` for the dataset object.\n",
        "        It simply returns the length of the internal `data` list, which represents\n",
        "        the preprocessed data after loading and filtering.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "      def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves a sample (image and corresponding age) at a given index.\n",
        "\n",
        "        This method overrides the default behavior of indexing for the dataset object.\n",
        "        It takes an index `idx` and performs the following:\n",
        "            1. Accesses the image name and age at the specified index from `self.data`.\n",
        "            2. Opens the image using `Image.open` with the full path constructed by\n",
        "               combining `self.root_dir` and `img_name`.\n",
        "            3. Applies the defined transformation (`self.transform`) to the image.\n",
        "            4. Normalizes the age by dividing by 100.\n",
        "            5. Creates a dictionary `sample` containing the preprocessed image (`image`)\n",
        "               and the normalized age as a PyTorch tensor (`torch.tensor(age).float()`).\n",
        "            6. Returns the constructed `sample` dictionary.\n",
        "        \"\"\"\n",
        "        img_name, age = self.data[idx]\n",
        "        image = Image.open(os.path.join(self.root_dir, img_name))\n",
        "        image = self.transform(image)\n",
        "        age = age / 100\n",
        "\n",
        "        sample = {'image': image, 'age': torch.tensor(age).float()}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the train/val/test dataloaders\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nAu80SXTkydg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI1xDbt1omPP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Define data transformations (augmentations for training and normalization)\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally for training augmentation\n",
        "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
        "    transforms.Normalize(  # Normalize pixel values based on ImageNet statistics\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize images to 256x256 (consistent with training)\n",
        "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
        "    transforms.Normalize(  # Normalize pixel values using the same statistics\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Set batch size\n",
        "bs = 32\n",
        "\n",
        "# Create datasets for training, validation, and testing\n",
        "print(\"Train set:\")\n",
        "trainset = FacesDataset(\"/content/imdb_crop\", transform_train, split=\"train\")\n",
        "print(\"Validation set:\")\n",
        "valset = FacesDataset(\"/content/imdb_crop\", transform_val, split=\"val\")\n",
        "print(\"Test set:\")\n",
        "testset = FacesDataset(\"/content/imdb_crop\", transform_val, split=\"test\")\n",
        "\n",
        "# Create data loaders for efficient batch training and evaluation\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Print dataset and dataloader lengths (number of samples and batches)\n",
        "print(f\"Number of training samples: {len(trainloader) * bs}\")\n",
        "print(f\"Number of validation samples: {len(valloader)}\")\n",
        "print(f\"Number of test samples: {len(testloader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCUcnKwBq2qX"
      },
      "source": [
        "2. Define a Neural Network (NN) [Mobilenet](https://pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v2.html#torchvision.models.mobilenet_v2) pretrained on Imagenet.\n",
        "\n",
        "Replace the last classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SoU5x1mq7QG"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model architecture (MobileNetV2)\n",
        "net = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')  # Load pre-trained weights\n",
        "\n",
        "# Adjust the final classification layer\n",
        "num_ftrs = net.classifier[1].in_features  # Get the number of input features for the last layer\n",
        "net.classifier = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 512),  # First linear layer with 512 units\n",
        "    nn.GELU(),  # GELU activation function\n",
        "    nn.Linear(512, 32),  # Second linear layer with 32 units\n",
        "    nn.GELU(),  # GELU activation function\n",
        "    nn.Linear(32, 1)   # Output layer with 1 unit (for age prediction)\n",
        ")\n",
        "\n",
        "# Move the model to the appropriate device (CPU or GPU)\n",
        "net.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY0BsgOXddiY"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "# Print model summary\n",
        "summary(net, (3, 256, 256))  # Input shape (channels, height, width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Y7sujZbMCM"
      },
      "source": [
        "**Transfer learning**\n",
        "\n",
        "Train only the last layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze pre-trained layers and unfreeze the classifier for fine-tuning\n",
        "for key, value in dict(net.named_children()).items():\n",
        "    if \"classifier\" in key:\n",
        "        for param in value.parameters():\n",
        "            param.requires_grad = True\n",
        "            print(f\"Unfreezing layer: {key}, Parameter shape: {param.shape}\")  # Print unfrozen layers (classifier)\n",
        "    else:\n",
        "        for param in value.parameters():\n",
        "            param.requires_grad = False\n",
        "            # print(param)  # Commented out to avoid printing individual parameters"
      ],
      "metadata": {
        "id": "dEpTEgQta5lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmA4DkACuPJB"
      },
      "source": [
        "Define a loss function and optimizer\n",
        "\n",
        "Let's use a Regression [L1Loss](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html) loss and [ADAM](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) optimizer. [learning rate scheduler](https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863#fad1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KpTZQWsbKYk"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim  # Optimization algorithms for training the model\n",
        "import torch.nn.functional as F  # Common loss functions and activation functions\n",
        "from scipy.stats import spearmanr, pearsonr  # Statistical functions for correlation calculation\n",
        "import itertools  # Utility functions for generating combinations\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR  # Learning rate scheduler for training\n",
        "import matplotlib.pyplot as plt  # Plotting library for visualization\n",
        "\n",
        "\n",
        "# Define training parameters (epochs, loss function, optimizer, and scheduler)\n",
        "epochs = 2  # Number of training epochs\n",
        "criterion = nn.L1Loss()  # L1 loss function for regression (mean absolute error)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
        "scheduler = CosineAnnealingLR(optimizer,\n",
        "                              T_max=len(trainloader) * epochs,  # Maximum number of iterations for scheduler\n",
        "                              eta_min=1e-5)  # Minimum learning rate for scheduler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmu1-dvfuPJB"
      },
      "source": [
        "**Fine-tuning**\n",
        "\n",
        "Train the network on the training data performing a validation at the end of each epoch. The evaluation is done using [PLCC](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) and [SROCC](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBQNNzHjbeQT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):  # Loop over the dataset for multiple epochs\n",
        "    running_loss = []  # List to store training loss for each batch\n",
        "    gt_labels = []  # List to store ground truth labels (predicted age)\n",
        "    pr_labels = []  # List to store predicted labels (model output)\n",
        "\n",
        "    net.train()  # Set the model to training mode (enables dropout and other training-specific behaviors)\n",
        "\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # Get inputs and labels from the data loader\n",
        "        inputs, labels = data[\"image\"], data[\"age\"]\n",
        "        gt_labels.append(labels.cpu().numpy())   # Append ground truth\n",
        "\n",
        "        inputs = inputs.to(device)  # Move data to the appropriate device (CPU or GPU)\n",
        "        labels = labels.to(device)  # Move labels to the appropriate device\n",
        "\n",
        "        # Zero the parameter gradients before each backward pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass, calculate loss\n",
        "        outputs = net(inputs)  # Get model predictions\n",
        "\n",
        "        loss = criterion(outputs.squeeze(), labels)  # Calculate L1 loss between predictions and true labels\n",
        "        pr_labels.append(outputs.squeeze().detach().cpu())  # Store predictions (detach to avoid gradients)\n",
        "\n",
        "        # Backward pass and parameter update\n",
        "        loss.backward()  # Backpropagate the loss\n",
        "        optimizer.step()  # Update model weights based on gradients\n",
        "        scheduler.step()  # Update learning rate according to the scheduler\n",
        "\n",
        "        # Print statistics (every 10% of the training data)\n",
        "        running_loss.append(loss.item())\n",
        "        if (i + 1) % (len(trainloader) // 10) == 0:  # Every 10% of the epoch\n",
        "            gt_labels = np.stack(list(itertools.chain.from_iterable(gt_labels))).squeeze()  # Combine ground truth labels\n",
        "            pr_labels = np.stack(list(itertools.chain.from_iterable(pr_labels))).squeeze()  # Combine predictions\n",
        "\n",
        "            # Calculate and print performance metrics (PLCC, SROCC, learning rate)\n",
        "            s = spearmanr(gt_labels, pr_labels)[0]  # Spearman Rank Correlation Coefficient\n",
        "            p = pearsonr(gt_labels, pr_labels)[0]  # Pearson Correlation Coefficient\n",
        "            print('%d, [%d, %d] loss: %.4f\\tPLCC: %.3f\\tSROCC: %.3f\\tlr: %.6f' %\n",
        "                  (epoch + 1, i + 1, len(trainloader), np.mean(running_loss), p, s, optimizer.param_groups[-1]['lr']))\n",
        "\n",
        "            # Clear lists for next iteration within the epoch\n",
        "            gt_labels = []\n",
        "            pr_labels = []\n",
        "            running_loss = []\n",
        "\n",
        "    # Validation loop (after each training epoch)\n",
        "    running_loss = []  # List to store validation loss for each batch\n",
        "    gt_labels = []  # List to store ground truth labels (predicted age)\n",
        "    pr_labels = []  # List to store predicted labels (model output)\n",
        "\n",
        "    net.eval()  # Set the model to evaluation mode (deactivates dropout and other training behaviors)\n",
        "\n",
        "    for i, data in enumerate(valloader):\n",
        "        # Get inputs and labels from the data loader\n",
        "        inputs, labels = data[\"image\"], data[\"age\"]\n",
        "        gt_labels.append(labels.item())  # Append ground truth as single values\n",
        "\n",
        "        inputs = inputs.to(device)  # Move data to the appropriate device\n",
        "        labels = labels.to(device)  # Move labels to the appropriate device\n",
        "\n",
        "        # Forward pass with gradient suppression\n",
        "        with torch.no_grad():\n",
        "            outputs = net(inputs)  # Get model predictions without calculating gradients\n",
        "\n",
        "        pr_labels.append(outputs.squeeze().item())  # Append predictions as single values\n",
        "        loss = criterion(outputs.squeeze(), labels.squeeze())  # Calculate L1 loss\n",
        "        running_loss.append(loss.item())\n",
        "\n",
        "    # Calculate and print validation performance metrics\n",
        "    gt_labels = np.stack(gt_labels)  # Combine ground truth labels\n",
        "    pr_labels = np.stack(pr_labels)  # Combine predictions\n",
        "    s = spearmanr(gt_labels, pr_labels)[0]  # Spearman Rank Correlation Coefficient\n",
        "    p = pearsonr(gt_labels, pr_labels)[0]  # Pearson Correlation Coefficient\n",
        "    print('Validation loss: %.6f\\tPLCC: %.3f\\tSROCC: %.3f' % (np.mean(running_loss), p, s))\n",
        "\n",
        "    # Visualization (optional)\n",
        "    plt.scatter(pr_labels, gt_labels)\n",
        "    plt.xlabel(\"AGE Predicted\")\n",
        "    plt.ylabel(\"AGE GT\")\n",
        "    plt.title(\"PLCC: %.3f\\nSROCC: %.3f\" % (p, s))\n",
        "    plt.show()\n",
        "\n",
        "    # Save the model (optional)\n",
        "    torch.save(net.state_dict(), f\"net_last_e{epoch}.pth\")  # Save model state after each epoch\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp4tYtJs9Flk"
      },
      "source": [
        "Evaluate on the test-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOmgjCHn9IDi"
      },
      "outputs": [],
      "source": [
        "# Testing loop (after training)\n",
        "running_loss = []  # List to store test loss for each batch\n",
        "gt_labels = []  # List to store ground truth labels (predicted age)\n",
        "pr_labels = []  # List to store predicted labels (model output)\n",
        "\n",
        "net.eval()  # Set the model to evaluation mode (deactivates dropout and other training behaviors)\n",
        "\n",
        "for i, data in enumerate(testloader):\n",
        "    # Get inputs and labels from the data loader\n",
        "    inputs, labels = data[\"image\"], data[\"age\"]\n",
        "    gt_labels.append(labels.item())  # Append ground truth as single values\n",
        "\n",
        "    inputs = inputs.to(device)  # Move data to the appropriate device\n",
        "    labels = labels.to(device)  # Move labels to the appropriate device\n",
        "\n",
        "    # Forward pass with gradient suppression\n",
        "    with torch.no_grad():\n",
        "        outputs = net(inputs)  # Get model predictions without calculating gradients\n",
        "\n",
        "    pr_labels.append(outputs.squeeze().item())  # Append predictions as single values\n",
        "    loss = criterion(outputs.squeeze(), labels.squeeze())  # Calculate L1 loss\n",
        "    running_loss.append(loss.item())\n",
        "\n",
        "# Calculate and print test performance metrics\n",
        "gt_labels = np.stack(gt_labels)  # Combine ground truth labels\n",
        "pr_labels = np.stack(pr_labels)  # Combine predictions\n",
        "s = spearmanr(gt_labels, pr_labels)[0]  # Spearman Rank Correlation Coefficient\n",
        "p = pearsonr(gt_labels, pr_labels)[0]  # Pearson Correlation Coefficient\n",
        "print('Test loss: %.6f\\tPLCC: %.3f\\tSROCC: %.3f' % (np.mean(running_loss), p, s))\n",
        "\n",
        "# Visualization (optional)\n",
        "plt.scatter(pr_labels, gt_labels)\n",
        "plt.xlabel(\"AGE Predicted\")\n",
        "plt.ylabel(\"AGE GT\")\n",
        "plt.title(\"PLCC: %.3f\\nSROCC: %.3f\" % (p, s))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_0hKaVXe7lc"
      },
      "source": [
        "**!ASSIGNMENT!**\n",
        "\n",
        "*Transfer learning*\n",
        "1. Finetune all the layers of the current network (mobilenet_v2).\n",
        "2. Swap out the current model with a new one from [here](https://pytorch.org/vision/main/models.html#classification) that is already trained on Imagenet. Then, fine-tune the network and compare how well it performs on the test-set compared to the current network (mobilenet_v2) using PLCC and SROCC metrics."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}