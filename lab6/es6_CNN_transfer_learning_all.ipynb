{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shbM3zJAuPI9"
   },
   "source": [
    "In this lab you will do the following steps in order:\n",
    "\n",
    "1. Load a new dataset using ``torchvision dataloader``\n",
    "2. Perform transfer learning of a pre-trained NN (Neural Network)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZW_s0fsB1Xi"
   },
   "source": [
    "\n",
    "Useful resources:\n",
    "\n",
    "* [dataloader](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)\n",
    "*   [network layers](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
    "*   [activation function](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
    "*   [loss functions](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F0vCe0kzcJ9"
   },
   "source": [
    "Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5bun1lQdwoqy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch  # Import the PyTorch library\n",
    "\n",
    "# Check if GPU (Graphics Processing Unit) is available for training\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "# Define the device to use for training based on GPU availability\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "\n",
    "# Print the chosen device for training\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYFtM4aXT0JM"
   },
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vDRKuw5pGBnW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-19 14:58:02--  https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7012157440 (6.5G) [application/x-tar]\n",
      "Saving to: ‘imdb_crop.tar’\n",
      "\n",
      "imdb_crop.tar       100%[===================>]   6.53G  3.23MB/s    in 52m 11s \n",
      "\n",
      "2024-04-19 15:50:12 (2.14 MB/s) - ‘imdb_crop.tar’ saved [7012157440/7012157440]\n",
      "\n",
      "--2024-04-19 15:50:13--  https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_meta.tar\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22937600 (22M) [application/x-tar]\n",
      "Saving to: ‘imdb_meta.tar’\n",
      "\n",
      "imdb_meta.tar       100%[===================>]  21.88M  5.25MB/s    in 3.8s    \n",
      "\n",
      "2024-04-19 15:50:17 (5.69 MB/s) - ‘imdb_meta.tar’ saved [22937600/22937600]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download images\n",
    "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n",
    "#download metadata\n",
    "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_meta.tar\n",
    "#extract\n",
    "!tar -xf imdb_crop.tar\n",
    "!tar -xf imdb_meta.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQBhFMSzpFFA"
   },
   "source": [
    "Remove grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySjydzAfS1mK"
   },
   "outputs": [],
   "source": [
    "import glob  # Import library for finding all files matching a pattern\n",
    "from PIL import Image  # Import library for image processing\n",
    "import numpy as np  # Import library for numerical operations (not used here)\n",
    "import os  # Import library for operating system functionalities\n",
    "\n",
    "# Define a path pattern to search for all jpg images within subdirectories of \"/content/imdb_crop\"\n",
    "image_path_pattern = \"/content/imdb_crop/*/*.jpg\"\n",
    "\n",
    "# Find all image file paths matching the pattern\n",
    "image_paths = glob.glob(image_path_pattern)\n",
    "\n",
    "# Iterate through each image path\n",
    "for image_path in image_paths:\n",
    "  # Open the image using Pillow's Image class\n",
    "  image = Image.open(image_path)\n",
    "\n",
    "  # Get the number of color channels in the image (e.g., RGB has 3 channels)\n",
    "  num_channels = len(image.getbands())\n",
    "\n",
    "  # Check if the image has a different number of channels than expected (likely grayscale or unsupported format)\n",
    "  if num_channels != 3:\n",
    "    # If not 3 channels, remove the image file\n",
    "    os.remove(image_path)\n",
    "    # print(f\"Removed {image_path} (not RGB format)\")  # Print statement to show removed files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEXVvskp2Q4s"
   },
   "source": [
    "Define function to convert numeric date to common date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qW-6cXo249Tz"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta  # Import libraries for date and time manipulation\n",
    "\n",
    "def datenum_to_datetime(datenum):\n",
    "  \"\"\"\n",
    "  Converts a date represented as a floating-point number (Excel-style) to a Python datetime object.\n",
    "\n",
    "  Args:\n",
    "      datenum (float): The date represented as a floating-point number.\n",
    "\n",
    "  Returns:\n",
    "      datetime: The converted datetime object (year only if conversion fails).\n",
    "          If conversion fails due to ValueError, TypeError, or OverflowError,\n",
    "          returns np.nan.\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    # Extract components from the datenum\n",
    "    days = datenum % 1  # Extract days (decimal part)\n",
    "    hours = days % 1 * 24  # Extract hours from remaining decimal part\n",
    "    minutes = hours % 1 * 60  # Extract minutes from remaining decimal part\n",
    "    seconds = minutes % 1 * 60  # Extract seconds from remaining decimal part\n",
    "\n",
    "    # Convert to datetime object with separate day, hour, minute, and second components\n",
    "    exact_date = (datetime.fromordinal(int(datenum))  # Convert integer part to date\n",
    "                 + timedelta(days=int(days))  # Add extracted days\n",
    "                 + timedelta(hours=int(hours))  # Add extracted hours\n",
    "                 + timedelta(minutes=int(minutes))  # Add extracted minutes\n",
    "                 + timedelta(seconds=round(seconds)))  # Add extracted seconds (rounded)\n",
    "\n",
    "    # Adjust for Excel's epoch being different from standard epoch (correct for year)\n",
    "    exact_date -= timedelta(days=366)\n",
    "\n",
    "    # Return the year from the converted datetime object\n",
    "    return exact_date.year\n",
    "\n",
    "  except (ValueError, TypeError, OverflowError) as e:\n",
    "    return np.nan  # Return np.nan if conversion fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEw-vwCipUeG"
   },
   "source": [
    "Define the [dataloader](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JAnWr6T0d8r"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import collections\n",
    "\n",
    "class FacesDataset(Dataset):\n",
    "      \"\"\"Face Landmarks dataset.\n",
    "\n",
    "      This class loads and preprocesses a dataset of face images with corresponding ages.\n",
    "      It supports train, validation, and test splits.\n",
    "      \"\"\"\n",
    "\n",
    "      def __init__(self, root_dir, transform, split):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory containing the images.\n",
    "            transform (callable, optional): Transformation to be applied to the images.\n",
    "            split (string): Split type (\"train\", \"val\", or \"test\").\n",
    "        \"\"\"\n",
    "        self.split=split\n",
    "        self.root_dir = root_dir\n",
    "        self.data = self.get_data()  # Load and preprocess data\n",
    "        total_data_len = int(len(self.data) * 0.5)  # Select small portion of the dataset\n",
    "\n",
    "        # Randomly shuffle indices for train/val/test split\n",
    "        idx = np.arange(total_data_len)\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(idx)\n",
    "        print(f\"Shuffled indices (first 5): {idx[:5]}\")  # Print first 5 shuffled indices\n",
    "\n",
    "        # Select data based on split\n",
    "        if split == \"train\":\n",
    "            self.data = self.data[idx[:int(total_data_len * 0.6)]]\n",
    "        elif split == \"val\":\n",
    "            self.data = self.data[int(total_data_len * 0.6):int(total_data_len * 0.8)]\n",
    "        else:\n",
    "            self.data = self.data[int(total_data_len * 0.8):]\n",
    "\n",
    "        # Analyze age distribution (uncomment to print)\n",
    "        # age_distribution = collections.Counter()\n",
    "        # for i, sample in enumerate(self.data):\n",
    "        #     age_distribution[sample[1]] += 1\n",
    "        # print(age_distribution)  # Uncomment to print the Counter object\n",
    "\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "\n",
    "      def get_data(self):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses data from the IMDB dataset (.MAT file).\n",
    "\n",
    "        This function performs the following steps:\n",
    "            1. Loads data from the MAT file using scipy.io.loadmat.\n",
    "            2. Defines column names for the loaded data.\n",
    "            3. Converts the loaded data into a dictionary.\n",
    "            4. Creates a pandas DataFrame for efficient data manipulation.\n",
    "            5. Prints DataFrame shape and the first few rows (before processing).\n",
    "            6. Converts date of birth to age using vectorized operations.\n",
    "            7. Filters images based on face score and presence of a single face.\n",
    "                - Removes images without a face (face_score != -np.inf).\n",
    "                - Ensures only one face is present (second_face_score.isna()).\n",
    "                - Filters based on minimum face score threshold (face_score >= 3.5).\n",
    "                - Filters for valid age range (0 <= age <= 100).\n",
    "                - Converts age to integer and drops unnecessary columns.\n",
    "            8. Constructs full image paths by prepending the root directory.\n",
    "            9. Filters for images with existing paths using vectorized boolean indexing.\n",
    "            10. Prints DataFrame shape and the first few rows (after processing).\n",
    "            11. Returns the preprocessed data as a NumPy array.\n",
    "        \"\"\"\n",
    "\n",
    "        # Load data from MAT file and define column names\n",
    "        mat_imdb = scipy.io.loadmat('/content/imdb/imdb.mat')\n",
    "        columns = [\"full_path\", \"dob\", \"photo_taken\", \"second_face_score\", \"face_score\"]\n",
    "\n",
    "        # Convert loaded data into a dictionary\n",
    "        data_dict = {col: mat_imdb['imdb'][0][0][col][0] for col in columns}\n",
    "\n",
    "        # Create pandas DataFrame for efficient data manipulation\n",
    "        df_imdb = pd.DataFrame(data_dict)\n",
    "        if self.split==\"train\":\n",
    "          print(\"Before processing:\")\n",
    "          print(df_imdb.shape)  # Print DataFrame shape\n",
    "          print(df_imdb.head())  # Print the first few rows\n",
    "\n",
    "        # Convert date of birth to age using vectorized operations\n",
    "        df_imdb['date_of_birth'] = df_imdb['dob'].apply(datenum_to_datetime)\n",
    "        df_imdb['age'] = df_imdb['photo_taken'].sub(df_imdb['date_of_birth'])  # Handle potential NaNs\n",
    "\n",
    "        # Filter images based on face score and presence of a single face\n",
    "        df_imdb = df_imdb[df_imdb['face_score'] != -np.inf]  # Remove images without a face\n",
    "        df_imdb = df_imdb[df_imdb['second_face_score'].isna()]  # Ensure only one face is present\n",
    "        df_imdb = df_imdb[df_imdb['face_score'] >= 3.5]  # Filter based on minimum face score threshold\n",
    "        df_imdb = df_imdb[(df_imdb['age'] <= 100) & (df_imdb['age'] >= 0)]  # Filter for valid age range\n",
    "        df_imdb['age'] = df_imdb['age'].apply(lambda x: int(x))  # Convert age to integer\n",
    "        df_imdb = df_imdb.drop(columns=['date_of_birth', 'dob', 'photo_taken', \"second_face_score\", \"face_score\"])  # Remove unnecessary columns\n",
    "\n",
    "        # Construct full image paths using vectorized operations\n",
    "        df_imdb['full_path'] = self.root_dir+\"/\"+ df_imdb['full_path'].apply(lambda x: x[0])\n",
    "\n",
    "        # Filter for images with existing paths using vectorized boolean indexing\n",
    "        df_imdb = df_imdb[df_imdb['full_path'].apply(os.path.exists)]\n",
    "\n",
    "        if self.split==\"train\":\n",
    "          print(\"After processing:\")\n",
    "          print(df_imdb.shape)  # Print DataFrame shape\n",
    "          print(df_imdb.head())  # Print the first few rows\n",
    "\n",
    "        return df_imdb.to_numpy()  # Return preprocessed data as a NumPy array\n",
    "\n",
    "      def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset (number of samples).\n",
    "\n",
    "        This method overrides the default behavior of `len` for the dataset object.\n",
    "        It simply returns the length of the internal `data` list, which represents\n",
    "        the preprocessed data after loading and filtering.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a sample (image and corresponding age) at a given index.\n",
    "\n",
    "        This method overrides the default behavior of indexing for the dataset object.\n",
    "        It takes an index `idx` and performs the following:\n",
    "            1. Accesses the image name and age at the specified index from `self.data`.\n",
    "            2. Opens the image using `Image.open` with the full path constructed by\n",
    "               combining `self.root_dir` and `img_name`.\n",
    "            3. Applies the defined transformation (`self.transform`) to the image.\n",
    "            4. Normalizes the age by dividing by 100.\n",
    "            5. Creates a dictionary `sample` containing the preprocessed image (`image`)\n",
    "               and the normalized age as a PyTorch tensor (`torch.tensor(age).float()`).\n",
    "            6. Returns the constructed `sample` dictionary.\n",
    "        \"\"\"\n",
    "        img_name, age = self.data[idx]\n",
    "        image = Image.open(os.path.join(self.root_dir, img_name))\n",
    "        image = self.transform(image)\n",
    "        age = age / 100\n",
    "\n",
    "        sample = {'image': image, 'age': torch.tensor(age).float()}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAu80SXTkydg"
   },
   "source": [
    "Build the train/val/test dataloaders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pI1xDbt1omPP"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define data transformations (augmentations for training and normalization)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally for training augmentation\n",
    "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
    "    transforms.Normalize(  # Normalize pixel values based on ImageNet statistics\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256 (consistent with training)\n",
    "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
    "    transforms.Normalize(  # Normalize pixel values using the same statistics\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Set batch size\n",
    "bs = 32\n",
    "\n",
    "# Create datasets for training, validation, and testing\n",
    "print(\"Train set:\")\n",
    "trainset = FacesDataset(\"/content/imdb_crop\", transform_train, split=\"train\")\n",
    "print(\"Validation set:\")\n",
    "valset = FacesDataset(\"/content/imdb_crop\", transform_val, split=\"val\")\n",
    "print(\"Test set:\")\n",
    "testset = FacesDataset(\"/content/imdb_crop\", transform_val, split=\"test\")\n",
    "\n",
    "# Create data loaders for efficient batch training and evaluation\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Print dataset and dataloader lengths (number of samples and batches)\n",
    "print(f\"Number of training samples: {len(trainloader) * bs}\")\n",
    "print(f\"Number of validation samples: {len(valloader)}\")\n",
    "print(f\"Number of test samples: {len(testloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCUcnKwBq2qX"
   },
   "source": [
    "2. Define a Neural Network (NN) [Mobilenet](https://pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v2.html#torchvision.models.mobilenet_v2) pretrained on Imagenet.\n",
    "\n",
    "Replace the last classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SoU5x1mq7QG"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the model architecture (MobileNetV2)\n",
    "net = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')  # Load pre-trained weights\n",
    "\n",
    "# Adjust the final classification layer\n",
    "num_ftrs = net.classifier[1].in_features  # Get the number of input features for the last layer\n",
    "net.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),  # First linear layer with 512 units\n",
    "    nn.GELU(),  # GELU activation function\n",
    "    nn.Linear(512, 32),  # Second linear layer with 32 units\n",
    "    nn.GELU(),  # GELU activation function\n",
    "    nn.Linear(32, 1)   # Output layer with 1 unit (for age prediction)\n",
    ")\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wY0BsgOXddiY"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# Print model summary\n",
    "summary(net, (3, 256, 256))  # Input shape (channels, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87Y7sujZbMCM"
   },
   "source": [
    "**Transfer learning**\n",
    "\n",
    "Train only the last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEpTEgQta5lC"
   },
   "outputs": [],
   "source": [
    "# Freeze pre-trained layers and unfreeze the classifier for fine-tuning\n",
    "for key, value in dict(net.named_children()).items():\n",
    "    if \"classifier\" in key:\n",
    "        for param in value.parameters():\n",
    "            param.requires_grad = True\n",
    "            print(f\"Unfreezing layer: {key}, Parameter shape: {param.shape}\")  # Print unfrozen layers (classifier)\n",
    "    else:\n",
    "        for param in value.parameters():\n",
    "            param.requires_grad = False\n",
    "            # print(param)  # Commented out to avoid printing individual parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmA4DkACuPJB"
   },
   "source": [
    "Define a loss function and optimizer\n",
    "\n",
    "Let's use a Regression [L1Loss](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html) loss and [ADAM](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) optimizer. [learning rate scheduler](https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863#fad1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KpTZQWsbKYk"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim  # Optimization algorithms for training the model\n",
    "import torch.nn.functional as F  # Common loss functions and activation functions\n",
    "from scipy.stats import spearmanr, pearsonr  # Statistical functions for correlation calculation\n",
    "import itertools  # Utility functions for generating combinations\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR  # Learning rate scheduler for training\n",
    "import matplotlib.pyplot as plt  # Plotting library for visualization\n",
    "\n",
    "\n",
    "# Define training parameters (epochs, loss function, optimizer, and scheduler)\n",
    "epochs = 2  # Number of training epochs\n",
    "criterion = nn.L1Loss()  # L1 loss function for regression (mean absolute error)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
    "scheduler = CosineAnnealingLR(optimizer,\n",
    "                              T_max=len(trainloader) * epochs,  # Maximum number of iterations for scheduler\n",
    "                              eta_min=1e-5)  # Minimum learning rate for scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmu1-dvfuPJB"
   },
   "source": [
    "**Fine-tuning**\n",
    "\n",
    "Train the network on the training data performing a validation at the end of each epoch. The evaluation is done using [PLCC](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) and [SROCC](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBQNNzHjbeQT"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):  # Loop over the dataset for multiple epochs\n",
    "    running_loss = []  # List to store training loss for each batch\n",
    "    gt_labels = []  # List to store ground truth labels (predicted age)\n",
    "    pr_labels = []  # List to store predicted labels (model output)\n",
    "\n",
    "    net.train()  # Set the model to training mode (enables dropout and other training-specific behaviors)\n",
    "\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # Get inputs and labels from the data loader\n",
    "        inputs, labels = data[\"image\"], data[\"age\"]\n",
    "        gt_labels.append(labels.cpu().numpy())   # Append ground truth\n",
    "\n",
    "        inputs = inputs.to(device)  # Move data to the appropriate device (CPU or GPU)\n",
    "        labels = labels.to(device)  # Move labels to the appropriate device\n",
    "\n",
    "        # Zero the parameter gradients before each backward pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass, calculate loss\n",
    "        outputs = net(inputs)  # Get model predictions\n",
    "\n",
    "        loss = criterion(outputs.squeeze(), labels)  # Calculate L1 loss between predictions and true labels\n",
    "        pr_labels.append(outputs.squeeze().detach().cpu())  # Store predictions (detach to avoid gradients)\n",
    "\n",
    "        # Backward pass and parameter update\n",
    "        loss.backward()  # Backpropagate the loss\n",
    "        optimizer.step()  # Update model weights based on gradients\n",
    "        scheduler.step()  # Update learning rate according to the scheduler\n",
    "\n",
    "        # Print statistics (every 10% of the training data)\n",
    "        running_loss.append(loss.item())\n",
    "        if (i + 1) % (len(trainloader) // 10) == 0:  # Every 10% of the epoch\n",
    "            gt_labels = np.stack(list(itertools.chain.from_iterable(gt_labels))).squeeze()  # Combine ground truth labels\n",
    "            pr_labels = np.stack(list(itertools.chain.from_iterable(pr_labels))).squeeze()  # Combine predictions\n",
    "\n",
    "            # Calculate and print performance metrics (PLCC, SROCC, learning rate)\n",
    "            s = spearmanr(gt_labels, pr_labels)[0]  # Spearman Rank Correlation Coefficient\n",
    "            p = pearsonr(gt_labels, pr_labels)[0]  # Pearson Correlation Coefficient\n",
    "            print('%d, [%d, %d] loss: %.4f\\tPLCC: %.3f\\tSROCC: %.3f\\tlr: %.6f' %\n",
    "                  (epoch + 1, i + 1, len(trainloader), np.mean(running_loss), p, s, optimizer.param_groups[-1]['lr']))\n",
    "\n",
    "            # Clear lists for next iteration within the epoch\n",
    "            gt_labels = []\n",
    "            pr_labels = []\n",
    "            running_loss = []\n",
    "\n",
    "    # Validation loop (after each training epoch)\n",
    "    running_loss = []  # List to store validation loss for each batch\n",
    "    gt_labels = []  # List to store ground truth labels (predicted age)\n",
    "    pr_labels = []  # List to store predicted labels (model output)\n",
    "\n",
    "    net.eval()  # Set the model to evaluation mode (deactivates dropout and other training behaviors)\n",
    "\n",
    "    for i, data in enumerate(valloader):\n",
    "        # Get inputs and labels from the data loader\n",
    "        inputs, labels = data[\"image\"], data[\"age\"]\n",
    "        gt_labels.append(labels.item())  # Append ground truth as single values\n",
    "\n",
    "        inputs = inputs.to(device)  # Move data to the appropriate device\n",
    "        labels = labels.to(device)  # Move labels to the appropriate device\n",
    "\n",
    "        # Forward pass with gradient suppression\n",
    "        with torch.no_grad():\n",
    "            outputs = net(inputs)  # Get model predictions without calculating gradients\n",
    "\n",
    "        pr_labels.append(outputs.squeeze().item())  # Append predictions as single values\n",
    "        loss = criterion(outputs.squeeze(), labels.squeeze())  # Calculate L1 loss\n",
    "        running_loss.append(loss.item())\n",
    "\n",
    "    # Calculate and print validation performance metrics\n",
    "    gt_labels = np.stack(gt_labels)  # Combine ground truth labels\n",
    "    pr_labels = np.stack(pr_labels)  # Combine predictions\n",
    "    s = spearmanr(gt_labels, pr_labels)[0]  # Spearman Rank Correlation Coefficient\n",
    "    p = pearsonr(gt_labels, pr_labels)[0]  # Pearson Correlation Coefficient\n",
    "    print('Validation loss: %.6f\\tPLCC: %.3f\\tSROCC: %.3f' % (np.mean(running_loss), p, s))\n",
    "\n",
    "    # Visualization (optional)\n",
    "    plt.scatter(pr_labels, gt_labels)\n",
    "    plt.xlabel(\"AGE Predicted\")\n",
    "    plt.ylabel(\"AGE GT\")\n",
    "    plt.title(\"PLCC: %.3f\\nSROCC: %.3f\" % (p, s))\n",
    "    plt.show()\n",
    "\n",
    "    # Save the model (optional)\n",
    "    torch.save(net.state_dict(), f\"net_last_e{epoch}.pth\")  # Save model state after each epoch\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp4tYtJs9Flk"
   },
   "source": [
    "Evaluate on the test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOmgjCHn9IDi"
   },
   "outputs": [],
   "source": [
    "# Testing loop (after training)\n",
    "running_loss = []  # List to store test loss for each batch\n",
    "gt_labels = []  # List to store ground truth labels (predicted age)\n",
    "pr_labels = []  # List to store predicted labels (model output)\n",
    "\n",
    "net.eval()  # Set the model to evaluation mode (deactivates dropout and other training behaviors)\n",
    "\n",
    "for i, data in enumerate(testloader):\n",
    "    # Get inputs and labels from the data loader\n",
    "    inputs, labels = data[\"image\"], data[\"age\"]\n",
    "    gt_labels.append(labels.item())  # Append ground truth as single values\n",
    "\n",
    "    inputs = inputs.to(device)  # Move data to the appropriate device\n",
    "    labels = labels.to(device)  # Move labels to the appropriate device\n",
    "\n",
    "    # Forward pass with gradient suppression\n",
    "    with torch.no_grad():\n",
    "        outputs = net(inputs)  # Get model predictions without calculating gradients\n",
    "\n",
    "    pr_labels.append(outputs.squeeze().item())  # Append predictions as single values\n",
    "    loss = criterion(outputs.squeeze(), labels.squeeze())  # Calculate L1 loss\n",
    "    running_loss.append(loss.item())\n",
    "\n",
    "# Calculate and print test performance metrics\n",
    "gt_labels = np.stack(gt_labels)  # Combine ground truth labels\n",
    "pr_labels = np.stack(pr_labels)  # Combine predictions\n",
    "s = spearmanr(gt_labels, pr_labels)[0]  # Spearman Rank Correlation Coefficient\n",
    "p = pearsonr(gt_labels, pr_labels)[0]  # Pearson Correlation Coefficient\n",
    "print('Test loss: %.6f\\tPLCC: %.3f\\tSROCC: %.3f' % (np.mean(running_loss), p, s))\n",
    "\n",
    "# Visualization (optional)\n",
    "plt.scatter(pr_labels, gt_labels)\n",
    "plt.xlabel(\"AGE Predicted\")\n",
    "plt.ylabel(\"AGE GT\")\n",
    "plt.title(\"PLCC: %.3f\\nSROCC: %.3f\" % (p, s))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_0hKaVXe7lc"
   },
   "source": [
    "**!ASSIGNMENT!**\n",
    "\n",
    "*Transfer learning*\n",
    "1. Finetune all the layers of the current network (mobilenet_v2).\n",
    "2. Swap out the current model with a new one from [here](https://pytorch.org/vision/main/models.html#classification) that is already trained on Imagenet. Then, fine-tune the network and compare how well it performs on the test-set compared to the current network (mobilenet_v2) using PLCC and SROCC metrics."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
